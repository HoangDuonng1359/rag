{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a25aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt thư viện\n",
    "!pip install -q langchain langchain-community langchain-core neo4j transformers accelerate bitsandbytes torch pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655e3513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duo/miniconda3/envs/rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Neo4j connection\n",
    "NEO4J_URI = \"neo4j+s://0c367113.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"gTO1K567hBLzkRdUAhhEb-UqvBjz0i3ckV3M9v_-Nio\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d4eb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã load 3770 chunks từ file luật giao thông\n",
      "Ví dụ chunk đầu tiên: 36_2024_QH15_art1\n",
      "Nội dung: Điều 1. Phạm vi điều chỉnh Luật này quy định về quy tắc, phương tiện, người tham gia giao thông đường bộ, chỉ huy, điều khiển, tuần tra, kiểm soát, giải quyết tai nạn giao thông đường bộ, trách nhiệm ...\n"
     ]
    }
   ],
   "source": [
    "chunk_file = \"/home/duo/work/DL/btl/data/chunk/chunks_by_clause.jsonl\"\n",
    "\n",
    "# Load JSONL file (mỗi dòng là một JSON object)\n",
    "chunks = []\n",
    "with open(chunk_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        chunk_data = json.loads(line.strip())\n",
    "        chunks.append(chunk_data)\n",
    "\n",
    "print(f\"Đã load {len(chunks)} chunks từ file luật giao thông\")\n",
    "print(f\"Ví dụ chunk đầu tiên: {chunks[0]['id']}\")\n",
    "print(f\"Nội dung: {chunks[0]['content'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qwen2.5 model từ Hugging Face\n",
    "print(\"Đang load model Qwen2.5-7B-Instruct...\")\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic schemas cho validation\n",
    "class Entity(BaseModel):\n",
    "    \"\"\"Schema cho một entity\"\"\"\n",
    "    name: str = Field(description=\"Tên thực thể\")\n",
    "    type: str = Field(description=\"Loại thực thể: VEHICLE (phương tiện), REGULATION (quy định), PENALTY (mức phạt), ROAD_ELEMENT (yếu tố đường), VIOLATION (vi phạm), ORGANIZATION (cơ quan)\")\n",
    "    description: str = Field(description=\"Mô tả về thực thể\")\n",
    "\n",
    "class Relationship(BaseModel):\n",
    "    \"\"\"Schema cho một relationship\"\"\"\n",
    "    source: str = Field(description=\"Tên entity nguồn\")\n",
    "    target: str = Field(description=\"Tên entity đích\")\n",
    "    type: str = Field(description=\"Loại quan hệ\")\n",
    "    description: str = Field(description=\"Mô tả quan hệ\")\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Schema cho toàn bộ knowledge graph output\"\"\"\n",
    "    entities: List[Entity] = Field(default_factory=list, description=\"Danh sách entities\")\n",
    "    relationships: List[Relationship] = Field(default_factory=list, description=\"Danh sách relationships\")\n",
    "\n",
    "print(\"Pydantic schemas đã sẵn sàng!\")\n",
    "print(f\"\\nSchema: {KnowledgeGraph.model_json_schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819cbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template để extract entities và relationships\n",
    "EXTRACTION_PROMPT = \"\"\"Phân tích văn bản luật giao thông đường bộ Việt Nam sau và trích xuất entities và relationships.\n",
    "\n",
    "QUY TẮC:\n",
    "- Chỉ trích xuất thông tin CÓ TRONG văn bản\n",
    "- Entity types: \n",
    "  + VEHICLE: phương tiện giao thông (xe máy, ô tô, xe thô sơ...)\n",
    "  + PENALTY: mức phạt, hình thức xử lý\n",
    "  + VIOLATION: hành vi vi phạm (vượt đèn đỏ, chạy quá tốc độ...)\n",
    "  + ROAD_ELEMENT: phần đường, làn đường, vỉa hè, biển báo...\n",
    "  + ORGANIZATION: cơ quan quản lý (Cảnh sát giao thông, Bộ GTVT...)\n",
    "- Relationship bao gồm types sau:\n",
    "  + BỊ_PHẠT: mối quan hệ giữa hành vi vi phạm và mức phạt\n",
    "  + KHÔNG_BỊ_PHẠT: mối quan hệ giữa hành vi và mức phạt không áp dụng\n",
    "  + ĐƯỢC_PHÉP: mối quan hệ giữa phương tiện và hành vi được phép thực hiện\n",
    "  + KHÔNG_ĐƯỢC_PHÉP: mối quan hệ giữa phương tiện và hành vi không được phép\n",
    "  + CẤM: mối quan hệ giữa phương tiện và hành vi bị cấm\n",
    "  Và các loại quan hệ khác nếu cần thiết, đảm bảo mô tả chính xác mối quan hệ giữa các entity.\n",
    "\n",
    "VĂN BẢN:\n",
    "{text}\n",
    "\n",
    "Hãy trả về kết quả theo ĐÚNG định dạng JSON sau (ĐẢM BẢO cú pháp JSON hợp lệ):\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\"name\": \"Xe máy\", \"type\": \"VEHICLE\", \"description\": \"Phương tiện giao thông cơ giới đường bộ\"}},\n",
    "    {{\"name\": \"Vượt đèn đỏ\", \"type\": \"VIOLATION\", \"description\": \"Hành vi vi phạm tín hiệu đèn giao thông\"}},\n",
    "    {{\"name\": \"Phạt tiền từ 4-6 triệu đồng\", \"type\": \"PENALTY\", \"description\": \"Mức phạt vi phạm đèn tín hiệu\"}}\n",
    "  ],\n",
    "  \"relationships\": [\n",
    "    {{\"source\": \"Xe máy\", \"target\": \"Vượt đèn đỏ\", \"type\": \"BỊ_PHẠT\", \"description\": \"Xe máy bị phạt khi vượt đèn đỏ\"}},\n",
    "    {{\"source\": \"Vượt đèn đỏ\", \"target\": \"Phạt tiền từ 4-6 triệu đồng\", \"type\": \"BỊ_PHẠT\", \"description\": \"Vi phạm đèn đỏ bị phạt tiền\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "CHỈ TRẢ VỀ JSON, KHÔNG GIẢI THÍCH THÊM:\"\"\"\n",
    "\n",
    "def generate_structured(prompt: str) -> str:\n",
    "    \"\"\"Generate text với Qwen model\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là một chuyên gia phân tích văn bản luật giao thông đường bộ Việt Nam. Trả về kết quả dưới dạng JSON hợp lệ.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=2046,  # Giảm để nhanh hơn\n",
    "            temperature=0.1,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0dfbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_knowledge(text: str, max_retries: int = 3) -> dict:\n",
    "    \"\"\"Extract entities và relationships từ text - validate với Pydantic, có retry khi lỗi\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Tạo prompt\n",
    "            prompt = EXTRACTION_PROMPT.format(text=text)\n",
    "            \n",
    "            # Generate response\n",
    "            response = generate_structured(prompt)\n",
    "            \n",
    "            # Parse JSON từ response\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                data = json.loads(json_str)\n",
    "                \n",
    "                # Validate với Pydantic\n",
    "                kg = KnowledgeGraph(**data)\n",
    "                \n",
    "                # Convert to dict\n",
    "                result = {\n",
    "                    \"entities\": [e.model_dump() for e in kg.entities],\n",
    "                    \"relationships\": [r.model_dump() for r in kg.relationships]\n",
    "                }\n",
    "                \n",
    "                # Thành công\n",
    "                if attempt > 0:\n",
    "                    print(f\"Retry thành công sau {attempt + 1} lần thử\")\n",
    "                return result\n",
    "            else:\n",
    "                print(f\"Không tìm thấy JSON (lần {attempt + 1}/{max_retries})\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    return {\"entities\": [], \"relationships\": []}\n",
    "                continue\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error (lần {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {\"entities\": [], \"relationships\": []}\n",
    "            continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error (lần {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                return {\"entities\": [], \"relationships\": []}\n",
    "            continue\n",
    "    \n",
    "    return {\"entities\": [], \"relationships\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm thêm entities và relationships vào Neo4j (tối ưu cho luật giao thông)\n",
    "def add_to_graph(knowledge: dict, chunk_metadata: dict):\n",
    "    \"\"\"Thêm knowledge vào Neo4j graph với metadata luật giao thông\"\"\"\n",
    "    \n",
    "    # Extract metadata\n",
    "    law_code = chunk_metadata.get('law_code', 'UNKNOWN')\n",
    "    law_name = chunk_metadata.get('law_name', '')\n",
    "    article = chunk_metadata.get('article', 0)\n",
    "    chapter = chunk_metadata.get('chapter', '')\n",
    "    chapter_title = chunk_metadata.get('chapter_title', '')\n",
    "    mode = chunk_metadata.get('mode', '')\n",
    "    has_penalty = chunk_metadata.get('has_penalty', False)\n",
    "    clauses = chunk_metadata.get('clauses', [])  # Lấy clauses thay vì vehicles\n",
    "    \n",
    "    # 1. Thêm entities KHÔNG CÓ metadata - chỉ name, type, description\n",
    "    for entity in knowledge.get('entities', []):\n",
    "        name = entity.get('name', '').strip()\n",
    "        entity_type = entity.get('type', 'UNKNOWN')\n",
    "        description = entity.get('description', '')\n",
    "        \n",
    "        if not name or len(name) < 2:  # Tránh entities quá ngắn\n",
    "            continue\n",
    "        \n",
    "        # Query đơn giản - chỉ MERGE theo name và type, không lưu metadata\n",
    "        query = f\"\"\"\n",
    "        MERGE (e:{entity_type} {{name: $name}})\n",
    "        ON CREATE SET \n",
    "            e.description = $description,\n",
    "            e.created_at = datetime()\n",
    "        ON MATCH SET\n",
    "            e.description = CASE \n",
    "                WHEN e.description IS NULL OR e.description = '' \n",
    "                THEN $description \n",
    "                ELSE e.description \n",
    "            END,\n",
    "            e.last_updated = datetime()\n",
    "        RETURN e.name as name\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            graph.query(query, {\n",
    "                'name': name,\n",
    "                'description': description\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding entity {name}: {e}\")\n",
    "    \n",
    "    # 2. Thêm relationships VỚI METADATA ĐẦY ĐỦ\n",
    "    for rel in knowledge.get('relationships', []):\n",
    "        source = rel.get('source', '').strip()\n",
    "        target = rel.get('target', '').strip()\n",
    "        rel_type = rel.get('type', 'RELATED_TO').replace(' ', '_').replace('-', '_').upper()\n",
    "        description = rel.get('description', '')\n",
    "        \n",
    "        if not source or not target or len(source) < 2 or len(target) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Query với MERGE relationship và lưu METADATA ĐẦY ĐỦ\n",
    "        query = f\"\"\"\n",
    "        MATCH (s {{name: $source}})\n",
    "        MATCH (t {{name: $target}})\n",
    "        MERGE (s)-[r:{rel_type}]->(t)\n",
    "        ON CREATE SET \n",
    "            r.description = $description,\n",
    "            r.mode = $mode,\n",
    "            r.law_name = $law_name,\n",
    "            r.law_code = $law_code,\n",
    "            r.chapter = $chapter,\n",
    "            r.chapter_title = $chapter_title,\n",
    "            r.article = $article,\n",
    "            r.clauses = $clauses,\n",
    "            r.has_penalty = $has_penalty,\n",
    "            r.created_at = datetime(),\n",
    "            r.occurrence_count = 1\n",
    "        ON MATCH SET\n",
    "            r.last_seen_article = $article,\n",
    "            r.occurrence_count = COALESCE(r.occurrence_count, 0) + 1,\n",
    "            r.last_updated = datetime()\n",
    "        RETURN type(r) as rel_type\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            graph.query(query, {\n",
    "                'source': source,\n",
    "                'target': target,\n",
    "                'description': description,\n",
    "                'mode': mode,\n",
    "                'law_name': law_name,\n",
    "                'law_code': law_code,\n",
    "                'chapter': chapter,\n",
    "                'chapter_title': chapter_title,\n",
    "                'article': article,\n",
    "                'clauses': clauses,\n",
    "                'has_penalty': has_penalty\n",
    "            })\n",
    "        except Exception as e:\n",
    "            # Nếu không tìm thấy entity, bỏ qua (có thể entity bị filter)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa dữ liệu cũ\n",
    "clear_old_data = False  # Đổi thành True nếu muốn xóa\n",
    "\n",
    "if clear_old_data:\n",
    "    graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"Đã xóa dữ liệu cũ\")\n",
    "else:\n",
    "    print(\"Giữ nguyên dữ liệu cũ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f10d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo indexes để tối ưu hiệu suất query\n",
    "print(\"Đang tạo indexes cho Neo4j...\")\n",
    "\n",
    "indexes = [\n",
    "    \"CREATE INDEX vehicle_name IF NOT EXISTS FOR (v:VEHICLE) ON (v.name)\",\n",
    "    \"CREATE INDEX violation_name IF NOT EXISTS FOR (v:VIOLATION) ON (v.name)\",\n",
    "    \"CREATE INDEX penalty_name IF NOT EXISTS FOR (p:PENALTY) ON (p.name)\",\n",
    "    \"CREATE INDEX regulation_name IF NOT EXISTS FOR (r:REGULATION) ON (r.name)\",\n",
    "    \"CREATE INDEX road_element_name IF NOT EXISTS FOR (r:ROAD_ELEMENT) ON (r.name)\",\n",
    "    \"CREATE INDEX organization_name IF NOT EXISTS FOR (o:ORGANIZATION) ON (o.name)\",\n",
    "]\n",
    "\n",
    "for idx_query in indexes:\n",
    "    try:\n",
    "        graph.query(idx_query)\n",
    "        print(f\"Đã tạo index\")\n",
    "    except Exception as e:\n",
    "        print(f\"Index có thể đã tồn tại: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\nIndexes đã sẵn sàng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2613145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BƯỚC 1: Extract knowledge và LƯU VÀO FILE JSON\n",
    "import os\n",
    "\n",
    "# Tạo thư mục output nếu chưa có\n",
    "os.makedirs('/data/graph_output', exist_ok=True)\n",
    "\n",
    "# File để lưu kết quả extraction\n",
    "output_file = '/data/graph_output/extracted_knowledge.jsonl'\n",
    "\n",
    "# Process chunks và lưu kết quả vào file\n",
    "start_chunk = 0  \n",
    "end_chunk = 30  \n",
    "total_entities = 0\n",
    "total_relationships = 0\n",
    "errors = 0\n",
    "\n",
    "num_chunks_to_process = min(end_chunk, len(chunks)) - start_chunk\n",
    "print(f\"Bắt đầu xử lý chunks từ {start_chunk} đến {end_chunk-1} (tổng {num_chunks_to_process})...\")\n",
    "print(f\"Kết quả sẽ được lưu vào: {output_file}\")\n",
    "\n",
    "# Mở file để ghi (mode 'w' để ghi đè, 'a' để append)\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for i in tqdm(range(start_chunk, min(end_chunk, len(chunks))), desc=\"Extracting knowledge\"):\n",
    "        chunk = chunks[i]\n",
    "        \n",
    "        try:\n",
    "            # Extract knowledge\n",
    "            knowledge = extract_knowledge(chunk['content'])\n",
    "            \n",
    "            # Tạo record để lưu\n",
    "            record = {\n",
    "                'chunk_id': chunk.get('id', i),\n",
    "                'chunk_index': i,\n",
    "                'metadata': chunk['metadata'],\n",
    "                'knowledge': knowledge\n",
    "            }\n",
    "            \n",
    "            # Ghi vào file JSONL (mỗi dòng là 1 JSON object)\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "            \n",
    "            # Stats\n",
    "            entities_count = len(knowledge.get('entities', []))\n",
    "            rels_count = len(knowledge.get('relationships', []))\n",
    "            total_entities += entities_count\n",
    "            total_relationships += rels_count\n",
    "            \n",
    "            # Print progress\n",
    "            if ((i - start_chunk + 1) % 5) == 0:\n",
    "                print(f\"\\nProgress after {i-start_chunk+1} chunks:\")\n",
    "                print(f\"   Entities extracted: {total_entities}\")\n",
    "                print(f\"   Relationships extracted: {total_relationships}\")\n",
    "                print(f\"   Errors: {errors}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            print(f\"\\nError at chunk {i}: {e}\")\n",
    "            # Lưu error record\n",
    "            error_record = {\n",
    "                'chunk_id': chunk.get('id', i),\n",
    "                'chunk_index': i,\n",
    "                'error': str(e),\n",
    "                'metadata': chunk['metadata']\n",
    "            }\n",
    "            f.write(json.dumps(error_record, ensure_ascii=False) + '\\n')\n",
    "            continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HOÀN TẤT EXTRACTION!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Thống kê:\")\n",
    "print(f\"   - Chunks xử lý: {num_chunks_to_process}\")\n",
    "print(f\"   - Tổng entities: {total_entities}\")\n",
    "print(f\"   - Tổng relationships: {total_relationships}\")\n",
    "print(f\"   - Errors: {errors}\")\n",
    "print(f\"   - Success rate: {((num_chunks_to_process - errors) / num_chunks_to_process * 100):.1f}%\")\n",
    "print(f\"\\nKết quả đã được lưu vào: {output_file}\")\n",
    "print(f\"Chạy cell tiếp theo để upload lên Neo4j!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BƯỚC 2: Load từ file JSON và UPLOAD LÊN NEO4J (với batch processing)\n",
    "\n",
    "# File chứa kết quả extraction\n",
    "input_file = '/home/duo/work/DL/btl/data/graph_output/extracted_knowledge.jsonl'\n",
    "\n",
    "# Batch size để giảm số lượng request (quan trọng cho Neo4j Aura Free)\n",
    "BATCH_SIZE = 10  # Có thể điều chỉnh tùy theo giới hạn\n",
    "\n",
    "print(f\"Đang load dữ liệu từ: {input_file}\")\n",
    "\n",
    "# Load tất cả records\n",
    "records = []\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line.strip())\n",
    "        # Chỉ lấy records có knowledge (bỏ qua error records)\n",
    "        if 'knowledge' in record:\n",
    "            records.append(record)\n",
    "\n",
    "print(f\"Đã load {len(records)} records hợp lệ\")\n",
    "\n",
    "# Upload lên Neo4j theo batch\n",
    "total_uploaded = 0\n",
    "total_entities_uploaded = 0\n",
    "total_relationships_uploaded = 0\n",
    "upload_errors = 0\n",
    "\n",
    "print(f\"\\nBắt đầu upload lên Neo4j (batch size: {BATCH_SIZE})...\")\n",
    "\n",
    "for batch_start in tqdm(range(0, len(records), BATCH_SIZE), desc=\"Uploading batches\"):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, len(records))\n",
    "    batch = records[batch_start:batch_end]\n",
    "    \n",
    "    # Process từng record trong batch\n",
    "    for record in batch:\n",
    "        try:\n",
    "            knowledge = record['knowledge']\n",
    "            metadata = record['metadata']\n",
    "            \n",
    "            # Add to graph\n",
    "            add_to_graph(knowledge, metadata)\n",
    "            \n",
    "            total_uploaded += 1\n",
    "            total_entities_uploaded += len(knowledge.get('entities', []))\n",
    "            total_relationships_uploaded += len(knowledge.get('relationships', []))\n",
    "            \n",
    "        except Exception as e:\n",
    "            upload_errors += 1\n",
    "            print(f\"\\nError uploading record {record.get('chunk_index', '?')}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Small delay giữa các batch để tránh rate limit\n",
    "    if batch_end < len(records):\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Progress report mỗi 5 batches\n",
    "    if ((batch_start // BATCH_SIZE + 1) % 5) == 0:\n",
    "        print(f\"\\nProgress: {total_uploaded}/{len(records)} records uploaded\")\n",
    "        print(f\"   Entities: {total_entities_uploaded}\")\n",
    "        print(f\"   Relationships: {total_relationships_uploaded}\")\n",
    "        print(f\"   Errors: {upload_errors}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HOÀN TẤT UPLOAD!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Thống kê:\")\n",
    "print(f\"   - Records uploaded: {total_uploaded}/{len(records)}\")\n",
    "print(f\"   - Tổng entities: {total_entities_uploaded}\")\n",
    "print(f\"   - Tổng relationships: {total_relationships_uploaded}\")\n",
    "print(f\"   - Upload errors: {upload_errors}\")\n",
    "print(f\"   - Success rate: {(total_uploaded / len(records) * 100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50683ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra kết quả trong Neo4j (tối ưu cho luật giao thông)\n",
    "print(\"=== Thống kê Entities theo loại ===\")\n",
    "count_query = \"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n)[0] as Type, count(n) as Count\n",
    "ORDER BY Count DESC\n",
    "\"\"\"\n",
    "results = graph.query(count_query)\n",
    "total_entities = 0\n",
    "for row in results:\n",
    "    print(f\"  {row['Type']}: {row['Count']}\")\n",
    "    total_entities += row['Count']\n",
    "print(f\"\\nTổng: {total_entities} entities\")\n",
    "\n",
    "print(\"\\n=== Thống kê Relationships ===\")\n",
    "rel_count_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN type(r) as RelType, count(r) as Count\n",
    "ORDER BY Count DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "rel_results = graph.query(rel_count_query)\n",
    "total_rels = 0\n",
    "for row in rel_results:\n",
    "    print(f\"  {row['RelType']}: {row['Count']}\")\n",
    "    total_rels += row['Count']\n",
    "print(f\"\\nTổng relationships (top 20): {total_rels}\")\n",
    "\n",
    "print(\"\\n=== Thống kê theo Luật (từ relationships) ===\")\n",
    "law_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE r.law_code IS NOT NULL\n",
    "RETURN r.law_code as LawCode, r.law_name as LawName, count(r) as Count\n",
    "ORDER BY Count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "law_results = graph.query(law_query)\n",
    "for row in law_results:\n",
    "    law_name = row.get('LawName', '')[:50]\n",
    "    print(f\"  {row['LawCode']}: {row['Count']} relationships - {law_name}\")\n",
    "\n",
    "print(\"\\n=== Thống kê Entities có mức phạt ===\")\n",
    "penalty_query = \"\"\"\n",
    "MATCH (p:PENALTY)\n",
    "RETURN count(p) as PenaltyCount\n",
    "\"\"\"\n",
    "penalty_results = graph.query(penalty_query)\n",
    "for row in penalty_results:\n",
    "    print(f\"  Tổng mức phạt: {row['PenaltyCount']}\")\n",
    "\n",
    "print(\"\\n=== Thống kê Vi phạm ===\")\n",
    "violation_query = \"\"\"\n",
    "MATCH (v:VIOLATION)\n",
    "OPTIONAL MATCH (v)-[r:BỊ_PHẠT]->(p:PENALTY)\n",
    "RETURN count(v) as ViolationCount, count(r) as WithPenalty\n",
    "\"\"\"\n",
    "violation_results = graph.query(violation_query)\n",
    "for row in violation_results:\n",
    "    print(f\"  Tổng vi phạm: {row['ViolationCount']}\")\n",
    "    print(f\"  Vi phạm có mức phạt: {row['WithPenalty']}\")\n",
    "\n",
    "print(\"\\n=== Thống kê theo Mode (từ relationships) ===\")\n",
    "mode_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE r.mode IS NOT NULL AND r.mode <> ''\n",
    "RETURN r.mode as Mode, count(r) as Count\n",
    "ORDER BY Count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "mode_results = graph.query(mode_query)\n",
    "for row in mode_results:\n",
    "    print(f\"  {row['Mode']}: {row['Count']} relationships\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20175ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân tích chi tiết các entities quan trọng\n",
    "print(\"=== Top 15 Vi phạm phổ biến nhất ===\")\n",
    "violation_query = \"\"\"\n",
    "MATCH (v:VIOLATION)\n",
    "OPTIONAL MATCH (v)-[r]-()\n",
    "WITH v, count(DISTINCT r) as rel_count\n",
    "RETURN v.name as Violation, v.description as Description, rel_count as Connections\n",
    "ORDER BY rel_count DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "violations = graph.query(violation_query)\n",
    "for i, row in enumerate(violations, 1):\n",
    "    desc = row.get('Description', '')[:60]\n",
    "    print(f\"{i:2d}. {row['Violation']} - {row['Connections']} kết nối\")\n",
    "    if desc:\n",
    "        print(f\"     {desc}\")\n",
    "\n",
    "print(\"\\n=== Top 10 Phương tiện được đề cập ===\")\n",
    "vehicle_query = \"\"\"\n",
    "MATCH (v:VEHICLE)\n",
    "OPTIONAL MATCH (v)-[r]-()\n",
    "WITH v, count(DISTINCT r) as rel_count\n",
    "RETURN v.name as Vehicle, v.description as Description, rel_count as Connections\n",
    "ORDER BY rel_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "vehicles = graph.query(vehicle_query)\n",
    "for i, row in enumerate(vehicles, 1):\n",
    "    desc = row.get('Description', '')[:40]\n",
    "    print(f\"{i:2d}. {row['Vehicle']} - {row['Connections']} kết nối\")\n",
    "\n",
    "print(\"\\n=== Top 10 Mức phạt ===\")\n",
    "penalty_query = \"\"\"\n",
    "MATCH (p:PENALTY)\n",
    "OPTIONAL MATCH (v)-[r:BỊ_PHẠT]->(p)\n",
    "WITH p, count(v) as violation_count\n",
    "RETURN p.name as Penalty, p.description as Description, violation_count as Violations\n",
    "ORDER BY violation_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "penalties = graph.query(penalty_query)\n",
    "for i, row in enumerate(penalties, 1):\n",
    "    desc = row.get('Description', '')[:50]\n",
    "    vio_count = row.get('Violations', 0)\n",
    "    print(f\"{i:2d}. {row['Penalty']}\")\n",
    "    print(f\"     Vi phạm liên quan: {vio_count}\")\n",
    "\n",
    "print(\"\\n=== Các quy định quan trọng ===\")\n",
    "regulation_query = \"\"\"\n",
    "MATCH (r:REGULATION)\n",
    "OPTIONAL MATCH (r)-[rel]-()\n",
    "WITH r, count(DISTINCT rel) as rel_count\n",
    "WHERE rel_count > 0\n",
    "RETURN r.name as Regulation, r.description as Description, rel_count as Connections\n",
    "ORDER BY rel_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "regulations = graph.query(regulation_query)\n",
    "for i, row in enumerate(regulations, 1):\n",
    "    desc = row.get('Description', '')[:50]\n",
    "    print(f\"{i:2d}. {row['Regulation']} - {row['Connections']} kết nối\")\n",
    "\n",
    "print(\"\\n=== Phân tích Relationships theo Article ===\")\n",
    "article_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE r.article IS NOT NULL\n",
    "WITH r.article as Article, r.law_code as LawCode, count(r) as RelCount\n",
    "RETURN Article, LawCode, RelCount\n",
    "ORDER BY RelCount DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "article_results = graph.query(article_query)\n",
    "for i, row in enumerate(article_results, 1):\n",
    "    print(f\"{i:2d}. Điều {row['Article']} ({row['LawCode']}): {row['RelCount']} relationships\")\n",
    "\n",
    "print(\"\\n=== Phân tích Relationships theo Chapter ===\")\n",
    "chapter_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE r.chapter IS NOT NULL AND r.chapter <> ''\n",
    "WITH r.chapter as Chapter, r.chapter_title as Title, count(r) as RelCount\n",
    "RETURN Chapter, Title, RelCount\n",
    "ORDER BY RelCount DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "chapter_results = graph.query(chapter_query)\n",
    "for i, row in enumerate(chapter_results, 1):\n",
    "    title = row.get('Title', '')[:40]\n",
    "    print(f\"{i:2d}. {row['Chapter']}: {row['RelCount']} relationships - {title}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
