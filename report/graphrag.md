# Graph RAG System - Há»‡ thá»‘ng Truy váº¥n Lá»‹ch sá»­ Viá»‡t Nam

## ğŸ“‹ Tá»•ng Quan

ÄÃ¢y lÃ  há»‡ thá»‘ng **Graph RAG (Retrieval-Augmented Generation)** Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» lá»‹ch sá»­ Viá»‡t Nam giai Ä‘oáº¡n 1945-1975. Há»‡ thá»‘ng káº¿t há»£p:

- **Knowledge Graph** (Neo4j) Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c entities vÃ  relationships
- **Vector Embeddings** (Sentence Transformers) Ä‘á»ƒ tÃ¬m kiáº¿m ngá»¯ nghÄ©a
- **Hybrid Retrieval** káº¿t há»£p graph traversal vÃ  semantic search
- **LLM (Gemini)** Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i tá»± nhiÃªn
- **Source Context** tá»« file gá»‘c chapter10.md

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Question                            â”‚
â”‚            "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m thÃ nh cÃ´ng do Ä‘Ã¢u?"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   HybridRetriever          â”‚
        â”‚  (graph_rag_hybrid.py)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚ Vector Search â”‚   â”‚
        â”‚  (Embeddings) â”‚   â”‚
        â”‚               â”‚   â”‚
        â”‚ EntityEmbedd- â”‚   â”‚
        â”‚   ings        â”‚   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
                 â”‚          â”‚
                 â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   â”‚ Graph Travers â”‚
                 â”‚   â”‚  (Cypher)     â”‚
                 â”‚   â”‚               â”‚
                 â”‚   â”‚ GraphRAGQuery â”‚
                 â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚          â”‚
                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Hybrid Scoring & Ranking   â”‚
        â”‚  - Vector similarity: 35%     â”‚
        â”‚  - Graph proximity: 25%       â”‚
        â”‚  - Entity type: 25%           â”‚
        â”‚  - Seed quality: 15%          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      ContextBuilder           â”‚
        â”‚   (graph_rag_context.py)      â”‚
        â”‚                               â”‚
        â”‚  1. Extract page numbers      â”‚
        â”‚  2. Load page content         â”‚
        â”‚  3. Format prompt             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Gemini API             â”‚
        â”‚   (graph_rag_gemini.py)       â”‚
        â”‚                               â”‚
        â”‚  Generate natural answer      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Answer                â”‚
        â”‚   "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m..."    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Cáº¥u TrÃºc Code

### 1. **graph_rag_embeddings.py** - Quáº£n lÃ½ Vector Embeddings

**Chá»©c nÄƒng:**
- Load model embedding (paraphrase-multilingual-mpnet-base-v2)
- Generate embeddings cho entities
- Semantic search dá»±a trÃªn cosine similarity
- LÆ°u vÃ  load embeddings tá»« Neo4j

**CÃ¡c method chÃ­nh:**
```python
class EntityEmbeddings:
    def semantic_search(query, top_k=10)
        # TÃ¬m entities tÆ°Æ¡ng tá»± vá»›i query
        # Returns: List[{name, type, description, similarity, first_seen_page}]
    
    def generate_embeddings_for_entities()
        # Generate embeddings cho táº¥t cáº£ entities trong graph
```

**Cáº­p nháº­t quan trá»ng:**
- Query Neo4j bÃ¢y giá» return `first_seen_page` vÃ  `first_seen_chapter`
- Káº¿t quáº£ semantic_search bao gá»“m page metadata

---

### 2. **graph_rag_query.py** - Graph Traversal vá»›i Cypher

**Chá»©c nÄƒng:**
- Query Neo4j báº±ng Cypher
- TÃ¬m related entities qua relationships
- TÃ¬m paths giá»¯a cÃ¡c entities

**CÃ¡c method chÃ­nh:**
```python
class GraphRAGQuery:
    def get_related_entities(entity_name, max_depth=1, limit=20)
        # Láº¥y cÃ¡c entities liÃªn quan qua relationships
        # Returns: List[{name, type, description, relationships, distance}]
    
    def find_paths_between_entities(source, target, max_length=3)
        # TÃ¬m Ä‘Æ°á»ng Ä‘i giá»¯a 2 entities
```

**Cáº­p nháº­t quan trá»ng:**
- Táº¥t cáº£ queries bÃ¢y giá» return `first_seen_page` vÃ  `first_seen_chapter`

---

### 3. **graph_rag_hybrid.py** - Hybrid Retrieval (CORE)

**ÄÃ¢y lÃ  thÃ nh pháº§n quan trá»ng nháº¥t**, káº¿t há»£p cáº£ 2 phÆ°Æ¡ng phÃ¡p retrieval.

#### Luá»“ng Hoáº¡t Äá»™ng Chi Tiáº¿t:

```python
def retrieve(question, top_k=15, vector_top_k=5, expansion_depth=1):
    """
    Phase 1: VECTOR SEARCH (Semantic Matching)
    ==========================================
    """
    # BÆ°á»›c 1.1: Infer question type
    q_type = infer_question_type(question)
    # VÃ­ dá»¥: "Ai lÃ£nh Ä‘áº¡o..." -> WHO
    #        "á» Ä‘Ã¢u..." -> WHERE
    #        "Khi nÃ o..." -> WHEN
    
    # BÆ°á»›c 1.2: Semantic search
    seed_entities = embeddings.semantic_search(question, top_k=vector_top_k)
    # Returns: Top 5 entities cÃ³ similarity cao nháº¥t
    # Example: [
    #   {name: "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m", similarity: 0.904, first_seen_page: 56},
    #   {name: "1945", similarity: 0.720, first_seen_page: 14},
    # ]
    
    """
    Phase 2: GRAPH EXPANSION (Context Enrichment)
    ==============================================
    """
    # BÆ°á»›c 2.1: Expand tá»« seed entities
    expanded = []
    for seed in seed_entities:
        # Láº¥y related entities qua graph relationships
        related = graph_query.get_related_entities(
            seed['name'], 
            max_depth=expansion_depth
        )
        expanded.extend(related)
    
    # BÆ°á»›c 2.2: Merge vÃ  deduplicate
    all_entities = seed_entities + expanded
    # unique by name
    
    """
    Phase 3: HYBRID SCORING (Intelligent Ranking)
    ==============================================
    """
    # BÆ°á»›c 3.1: Calculate hybrid score cho má»—i entity
    for entity in all_entities:
        # 3.1.1 Vector Score (35%)
        vector_score = seed_lookup.get(entity['name'], 0.0)
        
        # 3.1.2 Graph Score (25%)
        distance = entity.get('distance', 999)
        graph_score = max(0, 1.0 - distance * 0.2)
        
        # 3.1.3 Type Score (25%) - Question-aware
        type_weights = {
            'WHO': {'PERSON': 1.0, 'ORGANIZATION': 0.7},
            'WHERE': {'LOCATION': 1.0, 'EVENT': 0.5},
            'WHEN': {'TIME': 1.0, 'EVENT': 0.8},
            # ...
        }
        type_score = type_weights[q_type].get(entity['type'], 0.5)
        
        # 3.1.4 Source Score (15%) - Quality of seed
        source_similarity = entity.get('source_similarity', 0.5)
        
        # 3.1.5 Combine
        hybrid_score = (
            0.35 * vector_score +
            0.25 * graph_score +
            0.25 * type_score +
            0.15 * source_similarity
        )
        
        entity['score'] = hybrid_score
    
    # BÆ°á»›c 3.2: Sort by score vÃ  láº¥y top_k
    ranked = sorted(all_entities, key=lambda x: x['score'], reverse=True)
    top_entities = ranked[:top_k]
    
    """
    Phase 4: EXTRACT RELATIONSHIPS
    ================================
    """
    # BÆ°á»›c 4: Láº¥y relationships giá»¯a cÃ¡c entities Ä‘Ã£ chá»n
    relationships = []
    entity_names = {e['name'] for e in top_entities}
    
    for entity in top_entities:
        related = graph_query.get_related_entities(entity['name'])
        for rel in related:
            if rel['target'] in entity_names:
                relationships.append({
                    'source': entity['name'],
                    'target': rel['target'],
                    'type': rel['relationship_type'],
                    'description': rel.get('description', '')
                })
    
    return {
        'top_entities': top_entities,
        'relationships': relationships,
        'question_type': q_type
    }
```

**Cáº­p nháº­t quan trá»ng:**
- Khi build entity dict, bÃ¢y giá» copy `first_seen_page` vÃ  `first_seen_chapter` tá»« source
- CÃ³ 3 chá»— trong code cáº§n update Ä‘á»ƒ preserve page metadata:
  1. Khi expand graph (line 213-220)
  2. Khi score expanded entities (line 277-285)
  3. Khi add seed entities (line 291-301)

---

### 4. **graph_rag_context.py** - Context Builder & Prompt Formatter

**Chá»©c nÄƒng:**
- Build structured context tá»« retrieval results
- Load ná»™i dung thá»±c táº¿ tá»« source file (chapter10.md)
- Format thÃ nh prompts cho LLM

#### Luá»“ng Hoáº¡t Äá»™ng:

```python
def build_rag_context(question, retrieval_context):
    """
    BÆ°á»›c 1: Extract entities vÃ  relationships
    """
    entities = retrieval_context['top_entities'][:12]
    relationships = retrieval_context['relationships'][:20]
    
    """
    BÆ°á»›c 2: Extract vÃ  Load Page Content (QUAN TRá»ŒNG!)
    """
    sources = _extract_sources_with_content(entities)
    
    # Chi tiáº¿t _extract_sources_with_content:
    sources_dict = {}
    for entity in entities:
        # Láº¥y page number
        page_num = entity.get('first_seen_page') or entity.get('page')
        
        if page_num:
            # Load ná»™i dung thá»±c táº¿ tá»« file
            content = _load_page_content(page_num)
            
            sources_dict[page_num] = {
                'chapter': 10,
                'page': page_num,
                'citation': f"Chapter 10, Page {page_num}",
                'content': content  # Ná»™i dung tháº­t tá»« file!
            }
    
    return sorted(sources_dict.values(), key=lambda x: x['page'])
```

**Method `_load_page_content(page_number)`:**
```python
def _load_page_content(page_number, max_chars=1000):
    """Load ná»™i dung tá»« data/chapter10.md"""
    
    # Check cache
    if page_number in self.page_cache:
        return self.page_cache[page_number]
    
    # Read file
    with open('data/chapter10.md', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Extract content cho page nÃ y
    # Pattern: --- Page X --- [content] --- Page X+1 ---
    pattern = rf"--- Page {page_number} ---\n(.*?)(?=--- Page {page_number + 1} ---|$)"
    match = re.search(pattern, content, re.DOTALL)
    
    if match:
        page_content = match.group(1).strip()
        # Truncate náº¿u quÃ¡ dÃ i
        if len(page_content) > max_chars:
            page_content = page_content[:max_chars] + "..."
        
        # Cache Ä‘á»ƒ tá»‘i Æ°u
        self.page_cache[page_number] = page_content
        return page_content
    
    return f"[Page {page_number} content not found]"
```

**Format Prompt cho Gemini:**
```python
def format_for_gemini(context, prompt_type="qa"):
    """
    Structure cá»§a prompt:
    
    1. SYSTEM INSTRUCTIONS (Vietnamese)
    2. ENTITIES vá»›i descriptions
    3. RELATIONSHIPS vá»›i directions
    4. CONNECTIONS (paths náº¿u cÃ³)
    5. SOURCE CONTENT (Ná»™i dung thá»±c táº¿ tá»« file!) â† QUAN TRá»ŒNG!
    6. QUESTION
    """
    
    parts = []
    
    # System instructions
    parts.append("""
    Báº¡n lÃ  chuyÃªn gia lá»‹ch sá»­ Viá»‡t Nam.
    - Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context
    - Tráº£ lá»i chÃ­nh xÃ¡c, cÃ³ cÄƒn cá»©
    - TrÃ­ch dáº«n entities vÃ  relationships
    """)
    
    # Entities
    for entity in context['entities']:
        parts.append(f"{entity['name']} ({entity['type']})")
        parts.append(f"  Äá»™ liÃªn quan: {entity['score']:.3f}")
    
    # Relationships
    for rel in context['relationships']:
        parts.append(f"{rel['source']} --[{rel['type']}]--> {rel['target']}")
    
    # SOURCE CONTENT - Pháº§n quan trá»ng nháº¥t!
    if context.get('sources'):
        parts.append("\nSOURCE CONTENT (Ná»™i dung nguá»“n):")
        for source in context['sources']:
            parts.append(f"\n{source['citation']}")
            parts.append(f"   {source['content'][:800]}...")
            # ÄÃ¢y lÃ  ná»™i dung THá»°C Táº¾ tá»« sÃ¡ch lá»‹ch sá»­!
    
    # Question
    parts.append(f"\nCÃ‚U Há»I: {context['question']}")
    parts.append("\nTRáº¢ Lá»œI:")
    
    return "\n".join(parts)
```

---

### 5. **graph_rag_gemini.py** - LLM Integration

**Chá»©c nÄƒng:**
- Káº¿t ná»‘i vá»›i Gemini API
- Generate answer tá»« structured prompt
- Handle errors vÃ  safety settings

#### Luá»“ng Hoáº¡t Äá»™ng:

```python
def generate_answer(question, prompt_type="qa", max_tokens=8192):
    """
    Step 1: RETRIEVE CONTEXT
    ========================
    """
    retrieval_context = retriever.retrieve(
        question=question,
        top_k=10,
        vector_top_k=5,
        expansion_depth=1
    )
    # Returns: {top_entities, relationships, question_type}
    
    """
    Step 2: BUILD RAG CONTEXT
    ==========================
    """
    rag_context = builder.build_rag_context(
        question=question,
        retrieval_context=retrieval_context,
        max_entities=10,
        max_relationships=15
    )
    # Returns: {entities, relationships, sources with content}
    
    """
    Step 3: FORMAT PROMPT
    =====================
    """
    prompt = builder.format_for_gemini(
        context=rag_context,
        prompt_type=prompt_type
    )
    # Returns: Complete prompt vá»›i instructions, context, sources
    
    """
    Step 4: GENERATE WITH GEMINI
    =============================
    """
    response = model.generate_content(
        prompt,
        generation_config={
            "temperature": 0.7,
            "max_output_tokens": max_tokens  # 8192 for full answer
        }
    )
    
    answer = response.text
    
    # Check if truncated
    if response.candidates[0].finish_reason != FinishReason.STOP:
        print("âš ï¸ Response may be incomplete")
    
    return {
        'question': question,
        'answer': answer,
        'context': rag_context,
        'metadata': {
            'entities_used': len(rag_context['entities']),
            'relationships_used': len(rag_context['relationships']),
            'prompt_tokens': response.usage_metadata.prompt_token_count,
            'completion_tokens': response.usage_metadata.candidates_token_count
        }
    }
```

---

## ğŸ”„ Luá»“ng Hoáº¡t Äá»™ng Tá»•ng Thá»ƒ (End-to-End)

### Example: "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m nÄƒm 1945 thÃ nh cÃ´ng do Ä‘Ã¢u?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: Question Analysis                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Input: "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m nÄƒm 1945 thÃ nh cÃ´ng do Ä‘Ã¢u?"

â†’ Infer question type: WHY/EXPLAIN
â†’ Keywords: ["CÃ¡ch máº¡ng thÃ¡ng TÃ¡m", "1945", "thÃ nh cÃ´ng"]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: Vector Search (Semantic)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ Generate query embedding
â†’ Search in entity embeddings
â†’ Top 5 results:
  1. "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m nÄƒm 1945" (EVENT) - similarity: 0.904
  2. "1945" (TIME) - similarity: 0.720
  3. "KhÃ¡ng chiáº¿n chá»‘ng PhÃ¡p 1945-1954" (EVENT) - 0.719
  4. "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m" (EVENT) - 0.715
  5. "Viá»‡t Nam DÃ¢n chá»§ Cá»™ng hÃ²a" (ORG) - 0.680

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: Graph Expansion                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
For each seed entity:
  â†’ Query: MATCH (seed)-[r*1..1]-(related)
  â†’ Expand "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m nÄƒm 1945":
    - Connected to: "Há»“ ChÃ­ Minh" (LEADER)
    - Connected to: "Viá»‡t Minh" (LED_BY)
    - Connected to: "Nháº­t Báº£n Ä‘áº§u hÃ ng" (HAPPENED_AFTER)

Total expanded: 6 entities

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 4: Hybrid Scoring                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
For "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m":
  - Vector score: 0.904 Ã— 0.35 = 0.316
  - Graph score: 1.0 Ã— 0.25 = 0.250 (distance=0)
  - Type score: 0.8 Ã— 0.25 = 0.200 (EVENT for WHY)
  - Source score: 1.0 Ã— 0.15 = 0.150
  â†’ TOTAL: 0.916

Ranked top 10 entities with hybrid scores

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 5: Extract Relationships                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Find relationships between selected entities:
  - "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m" --[THÃ€NH_CÃ”NG]--> "Viá»‡t Nam DÃ¢n chá»§ Cá»™ng hÃ²a"
  - "Há»“ ChÃ­ Minh" --[LÃƒNH_Äáº O]--> "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m"
  - "1945" --[THá»œI_ÄIá»‚M]--> "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m"

Total: 4 relationships

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 6: Extract Page Numbers & Load Content               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
From entities, extract pages:
  - "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m": first_seen_page = 56
  - "1945": first_seen_page = 14
  - "Viá»‡t Nam DÃ¢n chá»§ Cá»™ng hÃ²a": first_seen_page = 56

Load content from data/chapter10.md:
  â†’ Page 56: "Tuáº§n lá»… vÃ ng (tá»« ngÃ y 16-9-1945)..."
  â†’ Page 14: "Viá»‡n Sá»­ há»c thuá»™c Viá»‡n HÃ n lÃ¢m..."

Total sources: 5 pages with content

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 7: Build Structured Context                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Context structure:
{
  "question": "CÃ¡ch máº¡ng thÃ¡ng TÃ¡m...",
  "question_type": "DEFAULT",
  "entities": [
    {name: "CÃ¡ch máº¡ng ThÃ¡ng TÃ¡m", type: "EVENT", score: 0.916},
    ...
  ],
  "relationships": [
    {source: "CÃ¡ch máº¡ng", target: "VNCH", type: "THÃ€NH_CÃ”NG"},
    ...
  ],
  "sources": [
    {
      "chapter": 10,
      "page": 56,
      "citation": "Chapter 10, Page 56",
      "content": "Tuáº§n lá»… vÃ ng (tá»« ngÃ y 16-9-1945)..."
    },
    ...
  ]
}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 8: Format Prompt for Gemini                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Prompt structure (Vietnamese):
  1. System instructions
  2. ENTITIES: 7 entities with scores
  3. RELATIONSHIPS: 4 relationships
  4. SOURCE CONTENT: 5 pages with actual text from book
  5. QUESTION
  6. Request for answer

Total: ~384 prompt tokens

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 9: Generate with Gemini                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†’ Send prompt to Gemini API
â†’ Generation config:
  - temperature: 0.7
  - max_output_tokens: 8192
  - model: gemini-2.5-flash

â†’ Generate answer...
â†’ Time: ~23 seconds
â†’ Output: 1836 tokens
â†’ Finish reason: STOP (complete)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 10: Return Structured Result                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
{
  "question": "...",
  "answer": "ChÃ o báº¡n, vá»›i vai trÃ² lÃ  chuyÃªn gia...",
  "context": {...},
  "metadata": {
    "retrieval_time": 5.83s,
    "generation_time": 23.27s,
    "total_time": 29.10s,
    "entities_used": 7,
    "relationships_used": 4,
    "prompt_tokens": 384,
    "completion_tokens": 1836
  }
}
```

---

## ğŸ¯ Äiá»ƒm Máº¡nh cá»§a Há»‡ Thá»‘ng

### 1. **Hybrid Retrieval**
- Káº¿t há»£p semantic search (vector) vá»›i graph traversal
- Táº­n dá»¥ng cáº£ similarity vÃ  structure relationships
- Question-aware scoring dá»±a trÃªn question type

### 2. **Source Context Integration**
- KhÃ´ng chá»‰ dá»±a vÃ o entities/relationships
- Load ná»™i dung thá»±c táº¿ tá»« sÃ¡ch gá»‘c (chapter10.md)
- LLM cÃ³ access Ä‘áº¿n raw text, tÄƒng Ä‘á»™ chÃ­nh xÃ¡c

### 3. **Intelligent Ranking**
- 4 yáº¿u tá»‘ scoring:
  - Vector similarity (35%): Semantic relevance
  - Graph proximity (25%): Structural importance  
  - Entity type (25%): Question-type matching
  - Seed quality (15%): Confidence from vector search

### 4. **Multi-level Context**
- Entities: What/Who
- Relationships: How they connect
- Paths: Indirect connections
- Source content: Actual evidence

---

## ğŸ“Š Performance Metrics

**Typical Query:**
- Retrieval time: ~5-7 seconds
  - Vector search: ~1s
  - Graph expansion: ~2s
  - Ranking: ~1s
  - Page loading: ~2s
  
- Generation time: ~20-25 seconds (Gemini API)

- Total: ~30 seconds per query

**Token Usage:**
- Average prompt: 300-500 tokens
- Average completion: 1500-2500 tokens
- Max output: 8192 tokens

---

## ğŸ”§ Configuration

### Neo4j Graph Schema:
```cypher
// Nodes
(:PERSON {name, description, first_seen_page, first_seen_chapter})
(:LOCATION {name, description, first_seen_page, first_seen_chapter})
(:ORGANIZATION {name, description, first_seen_page, first_seen_chapter})
(:EVENT {name, description, first_seen_page, first_seen_chapter})
(:TIME {name, description, first_seen_page, first_seen_chapter})

// Relationships
()-[r:LÃƒNH_Äáº O {description}]->()
()-[r:THÃ€NH_CÃ”NG {description}]->()
()-[r:THAM_GIA {description}]->()
// ... more relationship types
```

### Embedding Model:
```python
model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
dimension = 768
```

### Gemini Configuration:
```python
model = "gemini-2.5-flash"
temperature = 0.7
max_output_tokens = 8192
```

---

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### Basic Usage:
```python
from graph_rag_gemini import GeminiRAG
from graph_rag_hybrid import HybridRetriever
from graph_rag_context import ContextBuilder
from graph_rag_embeddings import EntityEmbeddings
from graph_rag_query import GraphRAGQuery

# Initialize components
graph_query = GraphRAGQuery(neo4j_graph)
embeddings = EntityEmbeddings(neo4j_graph)
hybrid = HybridRetriever(graph_query, embeddings)
builder = ContextBuilder(source_file="data/chapter10.md")

# Create RAG system
rag = GeminiRAG(
    hybrid_retriever=hybrid,
    context_builder=builder,
    model_name="gemini-2.5-flash"
)

# Ask question
result = rag.generate_answer(
    question="CÃ¡ch máº¡ng thÃ¡ng TÃ¡m thÃ nh cÃ´ng do Ä‘Ã¢u?",
    prompt_type="explain"
)

print(result['answer'])
```

---

## ğŸ› CÃ¡c Váº¥n Äá» ÄÃ£ Fix

### 1. **Page Info KhÃ´ng ÄÆ°á»£c Truyá»n**
**Váº¥n Ä‘á»:** Entities trong Neo4j cÃ³ `first_seen_page` nhÆ°ng khÃ´ng xuáº¥t hiá»‡n trong retrieval results.

**NguyÃªn nhÃ¢n:** 
- Query trong `graph_rag_embeddings.py` khÃ´ng SELECT page fields
- Query trong `graph_rag_query.py` khÃ´ng return page info
- `graph_rag_hybrid.py` khÃ´ng copy page info khi build entity dicts

**Giáº£i phÃ¡p:**
- âœ… Update táº¥t cáº£ Cypher queries Ä‘á»ƒ return `first_seen_page`, `first_seen_chapter`
- âœ… Update 3 chá»— trong hybrid.py khi build entity dicts
- âœ… Implement `_load_page_content()` trong context builder

### 2. **Gemini Response Bá»‹ Truncate**
**Váº¥n Ä‘á»:** CÃ¢u tráº£ lá»i bá»‹ cáº¯t ngang, khÃ´ng hoÃ n chá»‰nh.

**NguyÃªn nhÃ¢n:** 
- `max_output_tokens` trong generation_config quÃ¡ tháº¥p (2048)
- Finish reason = MAX_TOKENS

**Giáº£i phÃ¡p:**
- âœ… TÄƒng default `max_output_tokens` lÃªn 8192
- âœ… Add warning khi response incomplete
- âœ… Log finish reason Ä‘á»ƒ debug

---

## ğŸ“ Notes

- System cáº§n Neo4j database Ä‘Ã£ Ä‘Æ°á»£c populate vá»›i data
- Embeddings cáº§n Ä‘Æ°á»£c generate trÆ°á»›c (hoáº·c load tá»« database)
- Source file `data/chapter10.md` pháº£i cÃ³ format Ä‘Ãºng vá»›i `--- Page X ---` markers
- Gemini API key cáº§n Ä‘Æ°á»£c set trong environment variables

---

## ğŸ“ TÃ i Liá»‡u Tham Kháº£o

1. **Graph RAG Papers:**
   - "From Local to Global: A Graph RAG Approach to Query-Focused Summarization"
   - Microsoft GraphRAG

2. **Technologies:**
   - Neo4j Graph Database
   - Sentence Transformers
   - Google Gemini API
   - LangChain Community

3. **Vietnamese NLP:**
   - Multilingual embedding models
   - Vietnamese tokenization challenges

---

**TÃ¡c giáº£:** Graph RAG System for Vietnamese History  
**Version:** 1.0  
**Last Updated:** December 25, 2025
